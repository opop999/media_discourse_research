---
title: "UDPIPE Pre-processing"
---
Load necessary packages
```{r include=FALSE}
# Package names
packages <- c("dplyr", "stringr", "purrr", "tidyr", "parallel", "pbmcapply")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
```

# Processing regex-cleaned chunks with UDPIPE model (via API)
# Using RStudio jobs to parallelize 
```{r}
# Set up parameters for this job
udpipe_period <- "*"
udpipe_exclude <- FALSE

setwd("media_articles")

# Identify dataset chunks of interest
all_regex_chunks <- list.files(path = file.path("data", "regex_processed", "chunks"), pattern = "*.rds", full.names = TRUE) %>%
  .[grep(pattern = udpipe_period, ., invert = udpipe_exclude)] %>%
  sort()

# Run the script as a RStudio job
rstudioapi::jobRunScript(path = "udpipe_rstudio_jobs.R", importEnv = TRUE)
```

Integrity check: UDPIPE vs original Regex dataset
```{r}
# Read the Regex processed chunks back in, we only the id
list_of_regex_chunks <- list.files(path = "media_articles/data/regex_processed/chunks/", pattern = "*.rds", full.names = TRUE)

get_regex_ids <- function(chunk_path) {
  chunk_path %>%
    readRDS() %>%
    pull(article_id)
}

regex_doc_ids <- pbmclapply(list_of_regex_chunks, get_regex_ids, mc.cores = detectCores() - 1) %>% 
  reduce(c) %>%
  unique()

# Read the UDPIPE processed chunks back in, we only keep the id
list_of_udpipe_chunks <- list.files(path = "media_articles/data/udpipe_processed/chunks/", pattern = "*.rds", full.names = TRUE)

get_udpipe_ids <- function(chunk_path) {
  chunk_path %>%
    readRDS() %>%
    pull(doc_id) %>% 
    unique()

}

udpipe_doc_ids <- pbmclapply(list_of_udpipe_chunks, get_udpipe_ids, mc.cores = detectCores() - 1) %>% 
          unlist() %>%
          unique()


# Which documents were not processed with UDPIPE?
missing_udpipe <- setdiff(regex_doc_ids, udpipe_doc_ids)

saveRDS(missing_udpipe, "missing_udpipe.rds")
```

```{r}

# # Read the UDPIPE processed chunks back in, we only keep the id
# list_of_udpipe_chunks <- list.files(path = "media_articles/data/udpipe_processed/chunks/", pattern = "*.rds", full.names = TRUE)
# 
# chunks <- list_of_udpipe_chunks %>% 
#     .[grep(pattern = "2022-05", .)] %>% 
#   map_dfr(readRDS)
# 
# deduplicated <- chunks %>% distinct()
# 
# 
# chunks_n <- 7
# 
# indexing <- rep(1:chunks_n, length.out = nrow(deduplicated), each = ceiling(nrow(deduplicated)/chunks_n))
# 
# splitted <- split(deduplicated, indexing)
# 
# Write the dataset to chunks
pbmclapply(names(splitted), function(df) {
  saveRDS(distinct(splitted[[df]]), file = paste0("media_articles/data/udpipe_processed/chunks/udpipe_regex_full_articles_2022-05_part_", df, ".rds"))
}, mc.cores = detectCores() - 1)

```




```{r}
# Read the Regex processed chunks back in, only preserve the ones missing in UDPIPE'd dataset
get_missing_articles <- function(chunk_path) {
  chunk_path %>%
    readRDS() %>%
    filter(article_id %in% missing_udpipe)

}

missing_articles <- pbmclapply(list_of_regex_chunks, get_missing_articles, mc.cores = detectCores() - 1) %>% 
  bind_rows(.id = "chunk_nr")

```


```{r}
# Check which ids are collected for the specific period
full_articles_selected_period <- list.files(path = "media_articles/data/regex_processed/chunks", pattern = "*.rds", full.names = TRUE) %>%
  .[grep("2015", .)] %>%
  map_dfr(readRDS, .id = "filename")

full_articles_dates <- list.files(path = "../1.data_sources/media_articles/data/full/chunks/", pattern = "*.rds", full.names = TRUE) %>%
  map_dfr(readRDS) %>%
  select(PublishDate, Code)

filtered_dates <- full_articles_dates[full_articles_dates$Code %in% udpipe_df_ids, ]

summary(filtered_dates$PublishDate)

# Function to compare the two id vectors
xtab_set <- function(A, B) {
  both <- union(A, B)
  inA <- both %in% A
  inB <- both %in% B
  return(table(inA, inB))
}

xtab_set(delete_regex_doc_ids, delete_udpipe_doc_ids)

```

