---
title: "Named Entity Recognition of regex-cleaned chunks with NAMETAG model (via API)"
---

## Load necessary packages
```{r include=FALSE}
# Package names
packages <-
  c(
    "dplyr",
    "stringr",
    "purrr",
    "tidyr",
    "tidytext",
    "quanteda",
    "jsonlite",
    "ggplot2",
    "data.table",
    "plotly",
    "forcats",
    "ggwordcloud",
    "ggpubr"
  )

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

# Import media labels
media_labels <- readRDS("../1.data_sources/media_articles/data/media_type_labels/all_media_labels_with_doc_id.rds")

```


## Using RStudio jobs to parallelize 
```{r}
# Set up parameters for this job
ner_period <- "2022"
ner_exclude <- FALSE

setwd("named_entity_recognition")

# Identify dataset chunks of interest
all_chunks_path_ner <- list.files(path = file.path("../../2.data_transformations", "media_articles", "data", "regex_processed", "chunks"),
                              pattern = "*.rds",
                              full.names = TRUE) %>%
                              .[grep(pattern = ner_period, ., invert = ner_exclude)] %>%
                              sort()

all_chunks_name_ner <- list.files(path = file.path("../../2.data_transformations", "media_articles", "data", "regex_processed", "chunks"),
                              pattern = "*.rds",
                              full.names = FALSE) %>%
                              .[grep(pattern = ner_period, ., invert = ner_exclude)] %>%
                              sort()

# Run the script as a RStudio job
rstudioapi::jobRunScript(path = "ner_rstudio_jobs.R", importEnv = TRUE)
```

## Process the NER results with stemming to deal with duplicates
```{r}
max_words <- 5L # Set up the upper limit for the number of words that entity can consist of
columns <- paste0("word_", 1:max_words)
stemming_aggressive <- FALSE # Sets two levels of stemming within the Python script
ner_period <- "2022-(02|03|04)" # Which period we are interested? c("2015-(10|11|12)", "2022-(02|03|04)")
period_exclude <- FALSE
entity_types <- c("P", "io", "ic", "if", "gc", "gr", "gt", "gu")

# Read the NER-processed chunks back in
ner_df <- list.files(path = "named_entity_recognition/data/chunks/", pattern = "*.rds", full.names = TRUE) %>%
  .[grep(pattern = ner_period, ., invert = period_exclude)] %>%
  map_dfr(readRDS) %>%
  filter(ent_type %in% entity_types) %>% # Select entity of interest: https://ufal.mff.cuni.cz/~strakova/cnec2.0/ne-type-hierarchy.pdf
  mutate(ent_text = tolower(ent_text),
         words_n = str_count(ent_text, "\\S+")) %>%
  filter(between(words_n, 1, max_words)) %>%
  separate(ent_text, into = all_of(columns), remove = FALSE, sep = "\\s", extra = "drop", fill = "right") %>%
  mutate(across(all_of(columns), ~ str_replace(., "[[:punct:]]|[0-9]", NA_character_))) %>% # Optional: replace punctuation and digits with NA
  select(-c(ent_text, words_n))

# Import custom stemming script into Python
reticulate::py_run_string("from named_entity_recognition.czech_stemmer import cz_stem_list")
# Process all columns of interest with this script
reticulate::py_run_string("r.ner_df = r.ner_df.apply(lambda x: cz_stem_list(x, r.stemming_aggressive) if x.name in r.columns else x)")

# Create a summary of the most common entities
ner_summary_2015 <-  ner_df_2015 %>%
  inner_join(media_labels, by = "doc_id") %>% # Optional, if we want to summarize based on media types
  mutate(across(all_of(columns), na_if, "NA"),
         media_type = fct_collapse(media_type, alternative = c("antisystem", "political_tabloid"))) %>%
  unite("ent_text_stemmed", all_of(columns), sep = " ", na.rm = TRUE) %>%
  filter(ent_text_stemmed != "", media_type %in% c("mainstream", "alternative")) %>%
  group_by(media_type) %>% # Optional for media types
  count(ent_text_stemmed) %>%
  slice_max(n, n = 100) %>% # Optional for media types: Get top n entities per media type
  mutate(n_scaled = (n - min(n)) / (max(n) - min(n))) %>% # scale variables to get values between 0,1
  arrange(media_type)

saveRDS(ner_summary_2015, "named_entity_recognition/data/ner_summary_2015.rds")

# Create a summary of the most common entities
ner_summary_2022 <-  ner_df_2022 %>%
  inner_join(media_labels, by = "doc_id") %>% # Optional, if we want to summarize based on media types
  mutate(across(all_of(columns), na_if, "NA"),
         media_type = fct_collapse(media_type, alternative = c("antisystem", "political_tabloid"))) %>%
  unite("ent_text_stemmed", all_of(columns), sep = " ", na.rm = TRUE) %>%
  filter(ent_text_stemmed != "", media_type %in% c("mainstream", "alternative")) %>%
  group_by(media_type) %>% # Optional for media types
  count(ent_text_stemmed) %>%
  slice_max(n, n = 100) %>% # Optional for media types: Get top n entities per media type
  mutate(n_scaled = (n - min(n)) / (max(n) - min(n))) %>% # scale variables to get values between 0,1
  arrange(media_type)

saveRDS(ner_summary_2022, "named_entity_recognition/data/ner_summary_2022.rds")

```

NER Visualizations
```{r}
ner_summary_2022 <- readRDS("named_entity_recognition/data/ner_summary_2022.rds") %>% group_by(media_type) %>% slice_max(n_scaled, n = 50) %>% ungroup()
ner_summary_2015 <- readRDS("named_entity_recognition/data/ner_summary_2015.rds") %>% group_by(media_type) %>% slice_max(n_scaled, n = 50) %>% ungroup()

# Entities for 2015 period
set.seed(3859)
ggplot(ner_summary_2015, aes(label = ent_text_stemmed, size = n_scaled, color = n_scaled)) +
  geom_text_wordcloud(
    area_corr = TRUE,
    max_steps = 1,
    grid_size = 1,
    eccentricity = .9
  ) +
  scale_size_area(max_size = 18) +
  scale_color_continuous(type = "viridis") +
  facet_wrap(~media_type) +
  labs(title = "Entities in the Czech News Media Migration Coverage (October-December 2015)",
       subtitle = "Named Entity Recognition of person, institution & place entities. Split by media type, top 50, stemmed.",
       caption = "Data: Newton Media Archive, NameTag 2: Jana Straková, Milan Straka & Jan Hajič (2019), Czech stemmer: Jacques Savoy (2005)") +
  theme_void() +
  theme(plot.background = element_rect(fill = "grey90"),
        plot.title = element_text(face = "bold", size = 10, margin = margin(0, 0, 3, 0)),
        plot.subtitle = element_text(face = "italic", size = 8, margin = margin(0, 0, 10, 0)),
        plot.caption = element_text(size = 6),
        panel.border = element_rect(colour = "black",
                                    fill = NA,
                                    size = 0.5),
        plot.margin = margin(7, 30, 5, 5, "pt"))

ggsave("../5.write_up/presentation_CCL_march_2022/graphics/ner_2015.png", device = "png",
       width = 1920, height = 1080, units = "px")

# Entities for 2022 period
set.seed(3859)
ggplot(ner_summary_2022, aes(label = ent_text_stemmed, size = n_scaled, color = n_scaled)) +
  geom_text_wordcloud(
    area_corr = TRUE,
    max_steps = 1,
    grid_size = 1,
    eccentricity = .9
  ) +
  scale_size_area(max_size = 36) +
  scale_color_continuous(type = "viridis") +
  facet_wrap(~media_type) +
  labs(title = "Entities in the Czech News Media Migration Coverage (February-April 2022)",
       subtitle = "Named Entity Recognition of person, institution & place entities. Split by media type, top 50, stemmed.",
       caption = "Data: Newton Media Archive, NameTag 2: Jana Straková, Milan Straka & Jan Hajič (2019), Czech stemmer: Jacques Savoy (2005)") +
  theme_void() +
  theme(plot.background = element_rect(fill = "grey90"),
        plot.title = element_text(face = "bold", size = 10, margin = margin(0, 0, 3, 0)),
        plot.subtitle = element_text(face = "italic", size = 8, margin = margin(0, 0, 10, 0)),
        plot.caption = element_text(size = 6),
        panel.border = element_rect(colour = "black",
                                    fill = NA,
                                    size = 0.5),
        plot.margin = margin(7, 30, 5, 5, "pt"))

ggsave("../5.write_up/presentation_CCL_march_2022/graphics/ner_2022.png", device = "png",
       width = 1920, height = 1080, units = "px")
```
